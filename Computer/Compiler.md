Процессор — обрабатывает информацию, выполняет команды пользователя и следит за работой всех подключенных устройств. процессор может разобрать только машинный код — набор 0 и 1, записаны в определённом порядке.

В процессор поступают электрические сигналы. Сильный сигнал 1, а слабый — 0. Набор таких цифр обозначает какую-то команду. Процессор ее распознает и выполняет.

Программы для первых компьютеров выглядели как огромные наборы 0 и 1.

чтобы процессор понимал, какие команды записаны в программе, программисты создали компилятор — программу, которая преобразует программный код в машинный.

Преобразование программного кода в машинный= компиляцией. Компиляция только преобразует код. не запускает его на исполнение. он "статически" (без запуска) транслируется в машинный код. текст программы разбирается на части и анализируется, а затем генерируется код, понятный процессору.

Разбор -> Анализ -> Генерация

этапы компиляции на примере вычисления периметра прямоугольника:

#include <iostream>

int main()
{
    double a=2.5, b=5, P;
    P = 2 * (a + b);
    printf("Width of the rectangle - %4.1f", a);// => Width of the rectangle - 2.5
    printf("\nLength of the rectangle - %4.1f", b);// => Length of the rectangle - 5.0
    printf("\nPerimeter of the rectangle is %4.1f", P);// => Perimeter of the rectangle is 15.0
    return 0;
}

После запуска программы компилятору определить, какие команды в ней записаны. компилятор разделяет программу на слова и знаки — токены, и записывает их в список. процесс - лексическим анализом. задача — получить токены.

Затем компилятор читает список и ищет токен-операторы. оператор присваивания(=), арифметические операторы(+,-,*,/), оператор вывода(printf()) и другие. операторы работают с числами, текстом и переменными.

Компилятор понять, какие токены в списке связаны с токен-оператором. для каждого оператора строится специальная структура — логическое дерево или дерево разбора.

операция P = 2*(a + b) будет преобразована в логическое дерево:

![alt text](compiler-1.png)

каждое дерево нужно разобрать на команды, и каждую команду преобразовать в машинный код. Компилятор читать дерево снизу вверх и составляет список команд:

Взять переменную a, взять переменную b, сложить их
Взять результат сложения, взять число 2 и найти их произведение
Результат произведения присвоить (записать) в переменную P
Компилятор еще раз проверяет команды, находит ошибки и старается улучшить код. При завершении этого этапа, компилятор переводит каждую команду в набор 0 и 1. Наборы записываются в файл, который сможет прочитать и выполнить процессор.

10111011 00010001 00000001 10111001 00001101 00000000 10110100 00001110 10001010 00000111

программу с набором исполняемых команд, которая могла компилировать другие программы на Fortran, и улучшенную версию себя.

![alt text](compiler-2.png)


Ни один компилируемый язык программирования не обходится без компилятора. компиляторы работают с несколькими языками программирования.

процессоры отличаются друг от друга устройством, поэтому машинный код для одного процессора будет понятен, а для другого нет. операционных систем: одна и та же программа будет работать на Windows, но не запустится на Linux или MacOS.пользоваться тем компилятором, который работает с нужным процессором и операционной системой.

Если программа будет работать на нескольких операционных системах, кросс-компилятор — преобразует универсальный машинный код. Например, GNU Compiler Collection(сокращенно GCC) поддерживает C++, Objective-C, Java, Фортран, Ada, Go и поддерживает разную архитектуру процессоров.

Когда компилятор анализирует текст программы, он проверяет, соответствует ли запись оператора стандартам языка. Если найдено несоответствие, то компилятор выводит об этом информацию пользователю в виде ошибки. Когда вся программа разобрана, пользователь видит список ошибок, которые есть в коде, и может их исправить. Пока программист не исправит ошибки, компилятор не перейдет к следующему этапу — генерации машинного кода для процессора. Чаще всего компилятор показывает пользователю:

ошибки объявления переменных или отсутствие их начальных значений
ошибки несоответствия типов
ошибки неправильной записи операторов и функций
Иногда компилятор определяет код, который при выполнении дает неправильный результат. Но преобразовать такую программу в машинный код все-таки можно. компилятор показывает пользователю предупреждение.

Компилятор — переводчик между программистом и процессором. преобразует текст программы в машинный код, определяет ряд ошибок в программе и оптимизирует ее работу.

Компилятор - программа, выполняет преобразование текста программы в машинный код, без его запуска, статически. затем запускает программу на выполнение. Интерпретатор сразу запускает код и выполняет его в процессе чтения. Промежуточного этапа как в компиляции нет.



преимущество Java над другими языками — мультиплатформенность.

компьютер умеет исполнять только простейшие команды.

Для собак есть команды «Рядом», «Лапу» и другие, слыша которую собака делает что-то важное. У компьютера роль таких команд выполняют числа: каждая команда закодирована некоторым числом (его еще называют машинным кодом).

Писать программу в виде чисел сложно, придумали языки программирования и компиляторы. язык, понятен человеку, с другой — компилятору. Компилятор — специальная программа, которая переводит текст программы, написанный на языке программирования, в набор машинных кодов.

Обычно программист пишет программу на языке программирования, а затем запускает компилятор, который на основе написанных программистом файлов с кодом программы делает один файл с машинным кодом — окончательную (скомпилированную) программу.

Программа на языке C++ -> Компилятор -> Программа, состоящая из машинных кодов
Этапы компиляции для языка C++

Получившаяся в итоге программа сразу может выполняться на компьютере. Минус такого подхода в том, что код полученной программы сильно зависит от процессора и операционной системы. Программа, скомпилированная под Windows, не будет работать на телефоне с Android.

Если вы написали программу под Android, то на операционной системе Windows она не запустится!

Но у Java гораздо более инновационный подход.

Программа на языке Java -> Java‑компилятор -> Программа, состоящая из специальных кодов (байт‑код) -> Java VM -> Программа, состоящая из машинных кодов
Этапы компиляции для языка Java

Компилятор Java не компилирует все классы в одну программу из машинных кодов. Вместо этого он компилирует каждый класс по отдельности, и не в машинные коды, а в специальный промежуточный код (байт-код). Компиляция в машинный код выполняется при запуске программы.

А кто же компилирует программу в машинный код при ее запуске?

Для этого есть специальная программа под названием JVM (Java Virtual Machine) — Виртуальная Машина Java. Сначала запускают ее, а затем — программу, состоящую из байт-кода. А уже JVM перед выполнением нужной программы компилирует ее в машинный код.

Если у вас крутой процессор, который поддерживает больший набор машинных команд, то во время "второй компиляции" сгенерируется машинный код с учетом именно вашего процессора и ОС. Именно поэтому Java иногда быстрее С++, который сразу компилируется в машинный код и может использовать только самые распространение команды процессора.

1. Типовые ошибки при компиляции
Скорость и оптимизация кода нам пока что не сильно важна, а вот что важно, так это то, что компилятор проверяет вашу программу на ошибки. Он проверяет код на корректность и не пустит его дальше, если нашёл даже маленькую ошибку.

Пример ошибки:
Вы пытаетесь присвоить число переменной, которая может хранить только текст.

String userName = 42; // Ой! Нельзя так.
Компилятор сразу выдаст ошибку, что типы не соответствуют: Cannot implicitly convert type 'int' to 'string'.

Другой пример — опечатка в команде println:

System.out.printline("Привет!"); // Ошибка в названии метода
Компилятор скажет: "Нет такого метода — проверяй синтаксис!"


ARM против x86: В чем разница между двумя архитектурами процессоров?

мир процессоров разбит на два лагеря. Если вы смотрите это видео со смартфона, то для вас работает процессор на архитектуре ARM, а если с ноутбука, для вас трудится чип на архитектуре x86.

А теперь еще и Apple объявила, что переводит свои Mac на собственные процессоры Apple Silicon на архитектуре ARM. Мы уже рассказывали, почему так происходит. А сегодня давайте подробно разберемся, в чем принципиальные отличия x86 и ARM. И зачем Apple в это все вписалась?

большинство мобильных устройств, iPhone и Android'ы работают на ARM'е. Qualcomm, HUAWEI Kirin, Samsung Exynos и Apple A13/A14 Bionic — это все ARM-процессоры.

А вот на компьютере не так — там доминирует x86 под крылом Intel и AMD. Именно поэтому на телефоне мы не можем запустить Word с компьютера.

x86 — так называется по последним цифрам семейства классических процессоров Intel 70-80х годов.

набор инструкций, то есть язык который понимает процессор

x86 процессоры используют сложный набор инструкций, который называется CISC - Complex Instruction Set Computing.

ARM процессоры наоборот используют упрощенный набор инструкций — RISC - Reduced Instruction Set Computing.

Кстати ARM расшифровывается как Продвинутые RISC машины - Advanced RISC Machines.

Наборы инструкций ещё принято назвать архитектурой или ISA - Instruction Set Architecture.

Второе отличие — это микроархитектура. Что это такое?

От того на каком языке говорят процессоры, зависит и то, как они проектируются. Потому как для выполнения каждой инструкции на процессоре нужно расположить свой логический блок. Соответственно, разные инструкции — разный дизайн процессора. А дизайн — это и есть микроархитектура.

x86 — CISC
ARM — RISC

Итак, запомнили. Говорим x86 — подразумеваем архитектуру CISC, ARM — это RISC.

Но как так произошло, что процессоры стали говорить на разных языках?

История CISC

Памятка программиста, 1960-е годы. Цифровой (машинный) код «Минск-22».

Всё началось в 1960-х. Поначалу программисты работали с машинным кодом, то есть реально писали нолики и единички. Это быстро всех достало и появился Assembler. Низкоуровневый язык программирования, который позволял писать простые команды типа сложить, скопировать и прочее. Но программировать на Assembler'е тоже было несладко. Потому как приходилось буквально “за ручку” поэтапно описывать процессору каждое его действие.

Поэтому, если бы вы ужинали с процессором, и попросили передать его вам соль, это выглядело бы так:

Эй процессор, посмотри в центр стола.
Видишь соль? Возьми её.
Теперь посмотри на меня.
Отдай мне соль. — Ага, спасибо!
А теперь снова возьми у меня соль.
Поставь её откуда взял
Спасибо большое! Продолжай свои дела.
Кхм… Процессор, видишь перец?
И так далее....

В какой-то момент это всё задолбало программистов. И они решили: Хей, а почему бы нам просто не не написать инструкцию «Передай мне соль»? Так и сделали. Набор таких комплексных инструкций назвали CISC.

Этот подход стал настоящим спасением как для разработчиков, так и для бизнеса. Захотел клиент новую инструкцию — не проблема, были бы деньги — мы сделаем. А деньги у клиентов были.

Недостатки CISC

Но был ли такой подход оптимальным??? С точки зрения разработчиков — да. Но вот микроархитектура страдала.

Представьте, вы купили квартиру и теперь вам нужно обставить её мебелью. Площади мало, каждый квадратный метр на счету.  И вот представьте, если бы CISC-процессор обставил мебелью вам гостиную, он бы с одной стороны позаботился о комфорте каждого потенциального гостя и выделил бы для него своё персональное место.

С другой стороны, он бы не щадил бюджет. Диван для одного человека, пуф для другого, кушетка для третьего, трон из Игры Престолов для вашей Дейенерис. В этом случае площадь комнаты бы очень быстро закончилась. Чтобы разместить всех вам бы пришлось увеличивать бюджет и расширять зал. Это не рационально. Но самое главное, CISC-архитектура существует очень давно и те инструкции, которые были написаны в 60-х годах сейчас уже вообще не актуальны. Поэтому часть мебели, а точнее исполнительных блоков, просто не будут использоваться. Но многие из них там остаются. Поэтому появился RISC…

Преимущества RISC

С одной стороны писать на Assembler'е под RISC процессоры не очень-то удобно. Если в лоб сравнивать код, написанный под CISC и RISC процессоры, очевидно преимущество первого.

Так выглядит код одной и той же операции для x86 и ARM.

x86

MOV AX, 15; AH = 00, AL = 0Fh
AAA; AH = 01, AL = 05
RET

ARM
MOV R3, #10
AND R2, R0, #0xF
CMP R2, R3
IT LT
BLT elsebranch
ADD R2. #6
ADD R1. #1
elsebranch:
END

Но так было раньше. На ассемблере уже давно никто не пишет.  Сейчас за программистов всё это делают компиляторы, поэтому никаких сложностей с написанием кода под RISC-процессоры нет. Зато есть преимущества.

Представьте, что вы проектируете процессор. Расположение блоков на х86 выглядело бы так.

Каждый цветной квадрат — это отдельные команды. Их много и они разные. Как вы поняли, здесь мы уже говорим про микроархитектуру, которая вытекает из набора команд. А вот ARM-процессор скорее выглядит так.

Ему не нужны блоки, созданные для функций, написанных 50 лет назад.

По сути, тут блоки только для самых востребованных команд. Зато таких блоков много. А это значит, что можно одновременно выполнять больше базовых команд. А раритетные не занимают место.

Еще один бонус сокращенного набора RISC: меньше места на чипе занимает блок по декодированию команд. Да, для этого тоже нужно место. Архитектура RISC проще и удобнее, загибайте пальцы:

проще работа с памятью,
более богатая регистровая архитектура,
легче делать 32/64/128 разряды,
легче оптимизировать,
меньше энергопотребление,
проще масштабировать и делать отладку.

Для примера вот два процессора одного поколения. ARM1 и Intel 386. При схожей производительности ARM вдвое меньше по площади. А транзисторов на нем в 10 раз меньше: 25 тысяч против 275 тысяч. Энергопотребление тоже отличается на порядок: 0.1 Ватт против 2 Ватт у Intel. Шок.

Поэтому наши смартфоны, которые работают на ARM процессорах с архитектурой RISC, долго живут, не требуют активного охлаждения и такие быстрые.

Лицензирование

Но это все отличия технические. Есть отличия и организационные. Вы не задумывались почему для смартфонов так много производителей процессоров, а в мире ПК на x86 только AMD и Intel? Все просто — ARM это компания которая занимается лицензированием, а не производством.

Даже Apple приложила руку к развитию ARM. Вместе с Acorn Computers и VLSI Technology. Apple присоединился к альянсу из-за их грядущего устройства — Newton. Устройства, главной функцией которого было распознавание текста.

Даже вы можете начать производить свои процессоры, купив лицензию. А вот производить процессоры на x86 не может никто кроме синей и красной компании. меньше конкуренции, медленнее развитие.

ARM прекрасно справляется со смартфонами и планшетами, но как насчет компьютеров и серверов, где вся поляна исторически поделена? И зачем Apple вообще ломанулась туда со своим Apple Silicon.

Что сейчас?

Допустим мы решили, что архитектура ARM более эффективная и универсальная. Что теперь? x86 похоронен?

На самом деле, в Intel и AMD не дураки сидят. И сейчас под капотом современные CISC-процессоры очень похожи на RISC. Постепенно разработчики CISC-процессоров все-таки пришли к этому и начали делать гибридные процессоры, но старый хвост так просто нельзя сбросить.

Но уже достаточно давно процессоры Intel и AMD разбивают входные инструкции на более мелкие микро инструкции (micro-ops), которые в дальнейшем — сейчас вы удивитесь — исполняются RISC ядром.

Да-да, ребята! Те самые 4-8 ядер в вашем ПК — это тоже RISC-ядра!

Надеюсь, тут вы окончательно запутались. Но суть в том, что разница между RISC и CISC-дизайнами уже сейчас минимальна.

А что остается важным — так это микроархитектура. То есть то, насколько эффективно все организовано на самом камне.

Ну вы уже наверное знаете, что Современные iPad практически не уступают 15-дюймовым MacBook Pro с процессорами Core i7 и Core i9.

компания Ampere представила свой 80-ядерный ARM процессор. По заявлению производителя в тестах процессор Ampere показывает результат на 4% лучше, чем самый быстрый процессор EPYC от AMD и потребляет на 14% меньше энергии.

Компания Ampere лезет в сегменты Cloud и Workstation, и показывает там отличные цифры. Самый быстрый суперкомпьютер в мире сегодня работает на ARM ISA. С обратной стороны, Intel пытается все таки влезть в сегмент low power и для этого выпускает новый интересный процессор на микроархитектуре lakefield.

Пока у ноутбуков и процессоров от Intel есть одно неоспоримое достоинство - (охлаждение и) единство архитектуры. Пока на рынке ARM-процессоров существуют Qualcomm, Samsung, MediaTek, в мире x86 творится монополия и разработчикам сильно легче делать софт и игры под “взрослые” процессоры.

И Apple та компания, которая способна мотивировать достаточное количество разработчиков пилить под свой ARM. Но суть этого перехода скорее не в противостоянии CISC и RISC. Поскольку оба подхода сближаются, акцент смещается на микроархитектуру, которую делает Apple для своих мобильных устройств. микроархитектура у них крута. И они хотели бы ее использовать в своих компьютерах.

И если бы Intel лицензировал x86 за деньги другим людям, то вероятно Apple просто адаптировали свою текущую микроархитектуру под x86. Но так как они не могут этого сделать, они решили просто перейти на ARM. Проблема для нас с микроархитектурой в том, что она коммерческая тайна. И мы про нее ничего не знаем.

Спрос на ARM в итоге вырастет. Для индустрии это не просто важный шаг, а архиважный. Линус Торвальдс говорил, что пока рабочие станции не станут работать на ARM — на рынке серверов будут использовать x86.

И вот это случилось — в перспективе это миллионы долларов, вложенных в серверные решения. хорошо и для потребителей.
